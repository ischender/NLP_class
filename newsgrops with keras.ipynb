{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "[rec.sport.hockey]:\t\t \"From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu> ...\"\n",
      "[comp.sys.ibm.pc.hardware]:\t\t \"From: mblawson@midway.ecn.uoknor.edu (Matthew B Lawson) ...\"\n",
      "[talk.politics.mideast]:\t\t \"From: hilmi-er@dsv.su.se (Hilmi Eren) ...\"\n",
      "[comp.sys.ibm.pc.hardware]:\t\t \"From: guyd@austin.ibm.com (Guy Dawson) ...\"\n",
      "[comp.sys.mac.hardware]:\t\t \"From: Alexander Samuel McDiarmid <am2o+@andrew.cmu.edu> ...\"\n",
      "[sci.electronics]:\t\t \"From: tell@cs.unc.edu (Stephen Tell) ...\"\n",
      "[comp.sys.mac.hardware]:\t\t \"From: lpa8921@tamuts.tamu.edu (Louis Paul Adams) ...\"\n",
      "[rec.sport.hockey]:\t\t \"From: dchhabra@stpl.ists.ca (Deepak Chhabra) ...\"\n",
      "[rec.sport.hockey]:\t\t \"From: dchhabra@stpl.ists.ca (Deepak Chhabra) ...\"\n",
      "[talk.religion.misc]:\t\t \"From: arromdee@jyusenkyou.cs.jhu.edu (Ken Arromdee) ...\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    " \n",
    "print(len(news.data))\n",
    "# 18846\n",
    " \n",
    "print(len(news.target_names))\n",
    "# 20\n",
    " \n",
    "print(news.target_names)\n",
    "# ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    " \n",
    "for text, num_label in zip(news.data[:10], news.target[:10]):\n",
    "    print('[%s]:\\t\\t \"%s ...\"' % (news.target_names[num_label], text[:100].split('\\n')[0]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 384\n",
    "VALIDATION_SPLIT = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliosha/Envs/nlp/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(news.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(news.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 179209 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (18846, 1000)\n",
      "Shape of label tensor: (18846, 20)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(news.target))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = nlp(word).vector\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/matrix.npy', 'wb') as fp:\n",
    "    np.save(fp, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/matrix.npy', 'wb') as fp:\n",
    "#     embedding_matrix = np.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(news.target_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15077 samples, validate on 3769 samples\n",
      "Epoch 1/10\n",
      "15077/15077 [==============================] - 765s 51ms/step - loss: 2.9934 - acc: 0.0827 - val_loss: 2.9726 - val_acc: 0.0785\n",
      "Epoch 2/10\n",
      "15077/15077 [==============================] - 732s 49ms/step - loss: 2.7558 - acc: 0.1511 - val_loss: 3.4286 - val_acc: 0.1136\n",
      "Epoch 3/10\n",
      "15077/15077 [==============================] - 789s 52ms/step - loss: 2.5003 - acc: 0.2270 - val_loss: 2.7470 - val_acc: 0.1703\n",
      "Epoch 4/10\n",
      "15077/15077 [==============================] - 752s 50ms/step - loss: 2.2414 - acc: 0.3072 - val_loss: 2.1769 - val_acc: 0.3141\n",
      "Epoch 5/10\n",
      "15077/15077 [==============================] - 709s 47ms/step - loss: 1.9689 - acc: 0.3889 - val_loss: 2.0899 - val_acc: 0.3701\n",
      "Epoch 6/10\n",
      "15077/15077 [==============================] - 774s 51ms/step - loss: 1.7252 - acc: 0.4662 - val_loss: 1.7827 - val_acc: 0.4524\n",
      "Epoch 7/10\n",
      "15077/15077 [==============================] - 706s 47ms/step - loss: 1.4720 - acc: 0.5451 - val_loss: 1.6550 - val_acc: 0.4908\n",
      "Epoch 8/10\n",
      "15077/15077 [==============================] - 776s 51ms/step - loss: 1.2757 - acc: 0.6071 - val_loss: 1.6125 - val_acc: 0.5084\n",
      "Epoch 9/10\n",
      "15077/15077 [==============================] - 740s 49ms/step - loss: 1.0853 - acc: 0.6627 - val_loss: 1.5980 - val_acc: 0.5261\n",
      "Epoch 10/10\n",
      "15077/15077 [==============================] - 778s 52ms/step - loss: 0.9168 - acc: 0.7159 - val_loss: 1.8838 - val_acc: 0.4940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12126b0f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"kerasw2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,    14, 19415,   455,   559,    15,    29,\n",
       "         2552,  1240,  5609,    33,   322,   767,  2175,  2121,   871,\n",
       "         1343,    32,   251,    88,    77,    84, 12087,   455,   559,\n",
       "           15,     7,   122,   228,    63,     3,  2552,  1240,    20,\n",
       "          517,  3490,    50,     1,  1393,     3,    61,   437,     3,\n",
       "         1507,    50,     1,  1302,  2552,  3027,     3,     1,  2701,\n",
       "          309,     7,   122,   243, 16334,   175,     5,     4,   243,\n",
       "        19416,   268,     7,   122,   194,     2,   296,    37,   337,\n",
       "            2,   369,  4389,    22,     4,   243,     3,  7286,    12,\n",
       "            1,  2552,   349,    30,    20,  1502,   137,  2701,  1382,\n",
       "           90,     7,   397,  5987,    74,  2025,    13,   130,    56,\n",
       "            8,   140,   215,    90,    93,  1457,   770,  1963,    56,\n",
       "            8,    97,     4,   308,  9186,  1857,     2,  1306,     6,\n",
       "            1,  2327,  6760,   115,   348,  5987,    21,     4,   308,\n",
       "            3,  1857,     6,     1,   365,   658,     3,   467,   185,\n",
       "            1,  2552,    20,   194,     2,  1985,     1,    66,     3,\n",
       "         3215,   608,     7,    26,   132,  8755,    19,     2,   131,\n",
       "            1,  3280,  2000,     1,  1151,  1457,   770,   283,  2552,\n",
       "         1222]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.texts_to_sequences([news.data[0]])\n",
    "test = pad_sequences(test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(p_string):\n",
    "    to_predict = tokenizer.texts_to_sequences([p_string])\n",
    "    to_predict = pad_sequences(to_predict, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    prediction = model.predict(to_predict)\n",
    "    return news.target_names[prediction.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig_art = \"\"\"\n",
    "A program is trying to attract more women into coaching to match the strong recent growth in women's sport.\n",
    "\n",
    "Football Federation SA (FFSA) has just held its first female-only Asian Football Confederation C-licence coaching course.\n",
    "\n",
    "\"There's a lot of interest in the women's game from the excellent job the Matildas have done, and certainly at the local level as well, and it cries out as the game's growing for the female coaching base to grow as well,\" FFSA's John Mundy said.\n",
    "\n",
    "The C-licence program teaches basic skills and techniques so the coaches are able to work primarily with young players.\n",
    "\n",
    "\"It's part of a two-year project where our focus and priority is female coaching,\" Mr Mundy said.\n",
    "\n",
    "\"We're looking for some of these girls learning to coach to also be instructors on courses down the track.\"\n",
    "\n",
    " A group photo of soccer players.\n",
    "PHOTO: Cristiano dos Santos Rodrigues (L) with some of the program participants and other soccer players. (ABC News: Loukas Founten)\n",
    "Mr Mundy pushed for the course after noticing there were few female coaches in the local Women's National Premier League and no female head coaches for SA's state teams.\n",
    "\n",
    "\"We think we could get to a stage where we even see females coaching the male teams,\" he said.\n",
    "\n",
    "\"A good coach is a good coach so there's no reason why a female couldn't be coaching a male team, in my view.\"\n",
    "\n",
    "The first intake of 10 women included some school teachers interested in coaching.\n",
    "\n",
    "'Male-dominated industry needs balance'\n",
    "Program director Cristiano dos Santos Rodrigues, a former Adelaide United striker, said women benefited from the all-female coaching group.\n",
    "\n",
    "\"They talk more about football, they express their knowledge of football a bit more than if they are mixed with men,\" he said.\n",
    "\n",
    "\"When they are with men they feel a bit intimidated.\"\n",
    "\n",
    "Lauren Daniel, a soccer player for 12 years, got involved in the program hoping it might provide a pathway to coaching at national or international level.\n",
    "\n",
    "\"It's quite a male-dominated industry at the moment. I just think it was a lot more relaxed having just females there and some friends as well,\" the Adelaide teacher said.\n",
    "\n",
    "\"[It's] good to get more females involved so that young people can look up and realise women can be a coach and can be really good coaches as well.\"\n",
    "\n",
    "The Matildas have been coached by a woman just once in their 40-year history, when Hesterine de Reus from the Netherlands spent 15 months in the job.\n",
    "\n",
    "There are two female head coaches among the nine W-League teams — Heather Garriock at Canberra United and Brisbane's Mel Andreatta, this year's W-League premiership coach.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.hockey'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(ambig_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = \"\"\"Microsoft launched ARM-powered Windows 10 PCs with “all-day” battery life back in December. While HP, Asus, and Lenovo’s devices aren’t on sale just yet, we’re still waiting to hear more about the limitations of Windows 10 running on these new PCs. Microsoft published a full list of limitations last week, spotted first by Thurrott, that details what to expect from Windows 10 on ARM. This list must have been published by accident, as the software giant removed it over the weekend so only cached copies of the information are available.\n",
    "\n",
    "Only ARM64 drivers are supported. Windows 10 on ARM can run x86 apps, but it can’t use x86 drivers. That shouldn’t be a problem for most hardware, but if you have some older peripherals then it’s likely that driver support won’t be available. Windows 10 on ARM driver support will be more limited, and similar to what Windows 10 S provides.\n",
    "x64 apps are not supported. This is something we’ve known, but Windows 10 on ARM does not support emulation of x64 apps. Microsoft is planning to support these in the future at some point, though.\n",
    "Certain games and apps don’t work. Microsoft says that games and apps that use a version of OpenGL later than 1.1 or that require hardware-accelerated OpenGL won’t work on Windows 10 on ARM. Games that use anticheat technologies also won’t run on Windows 10 on ARM.\n",
    "Apps that customize the Windows experience may not work correctly. Apps like assistitive technologies or input method editors won’t work properly on Windows 10 on ARM. Also, apps that include shell extensions (icons and right-click menus in File Explorer) like Dropbox may fail. These apps will need to be compiled natively for ARM.\n",
    "Apps that assume that all ARM-based devices are running a mobile version of Windows may not work correctly. Some apps that have been coded for Windows Phone won’t work correctly and could appear in the wrong orientation or have UI layout problems. This won’t be a huge amount of apps, though.\n",
    "The Windows Hypervisor Platform is not supported on ARM. You won’t be able to run virtual machines using Hyper-V with Windows 10 on ARM.\n",
    "It seems that for most Windows users, Windows 10 on ARM will support common apps and scenarios. Microsoft’s emulation work allows you to download most 32-bit exe files from the web and install them on ARM-powered laptops. There are clearly some limitations, outlined above, but the majority of apps should run. We’re still waiting to test an ARM-powered Windows 10 laptop to see if the battery life is what has been promised, and whether performance for desktop apps is reasonable enough.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.os.ms-windows.misc'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey rec.sport.hockey\n",
      "sci.electronics comp.sys.ibm.pc.hardware\n",
      "rec.sport.hockey talk.politics.mideast\n",
      "comp.sys.ibm.pc.hardware comp.sys.ibm.pc.hardware\n",
      "comp.sys.ibm.pc.hardware comp.sys.mac.hardware\n",
      "sci.electronics sci.electronics\n",
      "misc.forsale comp.sys.mac.hardware\n",
      "rec.sport.hockey rec.sport.hockey\n",
      "rec.sport.hockey rec.sport.hockey\n",
      "talk.religion.misc talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "for i, el in enumerate(news.data[:10]):\n",
    "    print(get_result(el), news.target_names[news.target[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject: Re: ARMENIA SAYS IT COULD SHOOT DOWN TURKISH PLANES (Henrik)\\nLines: 95\\nNntp-Posting-Host: viktoria.dsv.su.se\\nReply-To: hilmi-er@dsv.su.se (Hilmi Eren)\\nOrganization: Dept. of Computer and Systems Sciences, Stockholm University\\n\\n\\n\\n\\n|>The student of \"regional killings\" alias Davidian (not the Davidian religios sect) writes:\\n\\n\\n|>Greater Armenia would stretch from Karabakh, to the Black Sea, to the\\n|>Mediterranean, so if you use the term \"Greater Armenia\" use it with care.\\n\\n\\n\\tFinally you said what you dream about. Mediterranean???? That was new....\\n\\tThe area will be \"greater\" after some years, like your \"holocaust\" numbers......\\n\\n\\n\\n\\n|>It has always been up to the Azeris to end their announced winning of Karabakh \\n|>by removing the Armenians! When the president of Azerbaijan, Elchibey, came to \\n|>power last year, he announced he would be be \"swimming in Lake Sevan [in \\n|>Armeniaxn] by July\".\\n\\t\\t*****\\n\\tIs\\'t July in USA now????? Here in Sweden it\\'s April and still cold.\\n\\tOr have you changed your calendar???\\n\\n\\n|>Well, he was wrong! If Elchibey is going to shell the \\n|>Armenians of Karabakh from Aghdam, his people will pay the price! If Elchibey \\n\\t\\t\\t\\t\\t\\t    ****************\\n|>is going to shell Karabakh from Fizuli his people will pay the price! If \\n\\t\\t\\t\\t\\t\\t    ******************\\n|>Elchibey thinks he can get away with bombing Armenia from the hills of \\n|>Kelbajar, his people will pay the price. \\n\\t\\t\\t    ***************\\n\\n\\n\\tNOTHING OF THE MENTIONED IS TRUE, BUT LET SAY IT\\'s TRUE.\\n\\t\\n\\tSHALL THE AZERI WOMEN AND CHILDREN GOING TO PAY THE PRICE WITH\\n\\t\\t\\t\\t\\t\\t    **************\\n\\tBEING RAPED, KILLED AND TORTURED BY THE ARMENIANS??????????\\n\\t\\n\\tHAVE YOU HEARDED SOMETHING CALLED: \"GENEVA CONVENTION\"???????\\n\\tYOU FACIST!!!!!\\n\\n\\n\\n\\tOhhh i forgot, this is how Armenians fight, nobody has forgot\\n\\tyou killings, rapings and torture against the Kurds and Turks once\\n\\tupon a time!\\n      \\n       \\n\\n|>And anyway, this \"60 \\n|>Kurd refugee\" story, as have other stories, are simple fabrications sourced in \\n|>Baku, modified in Ankara. Other examples of this are Armenia has no border \\n|>with Iran, and the ridiculous story of the \"intercepting\" of Armenian military \\n|>conversations as appeared in the New York Times supposedly translated by \\n|>somebody unknown, from Armenian into Azeri Turkish, submitted by an unnamed \\n|>\"special correspondent\" to the NY Times from Baku. Real accurate!\\n\\nOhhhh so swedish RedCross workers do lie they too? What ever you say\\n\"regional killer\", if you don\\'t like the person then shoot him that\\'s your policy.....l\\n\\n\\n|>[HE]\\tSearch Turkish planes? You don\\'t know what you are talking about.<-------\\n|>[HE]\\tsince it\\'s content is announced to be weapons? \\t\\t\\t\\ti\\t \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n|>Well, big mouth Ozal said military weapons are being provided to Azerbaijan\\ti\\n|>from Turkey, yet Demirel and others say no. No wonder you are so confused!\\ti\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\tConfused?????\\t\\t\\t\\t\\t\\t\\t\\ti\\n\\tYou facist when you delete text don\\'t change it, i wrote:\\t\\ti\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\n        Search Turkish planes? You don\\'t know what you are talking about.\\ti\\n        Turkey\\'s government has announced that it\\'s giving weapons  <-----------i\\n        to Azerbadjan since Armenia started to attack Azerbadjan\\t\\t\\n        it self, not the Karabag province. So why search a plane for weapons\\t\\n        since it\\'s content is announced to be weapons?   \\n\\n\\tIf there is one that\\'s confused then that\\'s you! We have the right (and we do)\\n\\tto give weapons to the Azeris, since Armenians started the fight in Azerbadjan!\\n \\n\\n|>You are correct, all Turkish planes should be simply shot down! Nice, slow\\n|>moving air transports!\\n\\n\\tShoot down with what? Armenian bread and butter? Or the arms and personel \\n\\tof the Russian army?\\n\\n\\n\\n\\nHilmi Eren\\nStockholm University\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.hockey'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target_names[news.target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
